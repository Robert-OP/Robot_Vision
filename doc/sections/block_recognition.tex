
\chapter{Block recognition}\label{ch:block_recognition}

The block recognition part has been divided into 5 main steps: 
\begin{itemize}
  \item background substraction
  \item color detection
  \item edge detection
  \item position
  \item orientation
\end{itemize}

\section{Background substraction}
As a first step a background substraction was performed, such that the gray area around the blocks is neglected and a proper color detection is applied. Also, this deals with the uneven illumination in the images which results in smoother edges. 

This is done by substracting the 2D median filtered image from the initial one as in Equation \ref{eq:rem_alg}. In the case of the white block, the background substraction partially erases the block's shape. However, it will be reconstructed later in the edge detection stage. 

\begin{equation}\label{eq:rem_alg}
  \begin{cases}
    Image(x,y) = I(x,y) - \overline{I(x,y)} \\
    \overline{I(x,y)} = medfilt2(I(x,y))
  \end{cases}
\end{equation}

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.35]{figures/remove_background.png}
  \caption{Camera image with background substracted}
  \label{fig:rem_back}
\end{figure}

\section{Color detection}

 	Once the background is substracted, the color of the blocks is experimentally obtained by using the tool \textit{Pixel region} in MATLAB. A color can be described with values between 0 and 255 for its primary colors, red, green and blue. Thus, for each block, the \textit{Pixel region} tool has been placed on it to get a range for the RGB parameters.\par

An example with the yellow block is given below
\par

\begin{figure}[hb]
  \centering
  \includegraphics[scale=0.3]{figures/Thres_Y_manualy2.png}
  \caption[LABEL] {RGB selection}
  \label{fig:color1}
\end{figure}

Figure \ref{fig:color1} gives us more or less a range for the RGB parameters. These parameters are then used to check in a loop (thresholding) that every pixel of the image are within the ranges.\par
%In the image below the pixels being in the RGB parameter are highlighted in white while the others are put into black. 

\begin{figure}[hb]
  \centering
  \includegraphics[scale=0.3]{figures/Thres_Y_bad2.png}
  \caption[LABEL] {First attempt color thresholding}
  \label{fig:color2}
\end{figure}
  

In figure \ref{fig:color2}, the 6 yellow blocks are detected. However, the one on the left is partially detected. This is the consequence of the different lightings in the robot cell. The RBG range was defined on a block placed in a zone of shadow (see the red arrow on the picture). \par


Thus, the color recognition was redefined taking into account the different lightings inside the robot cell. All the yellow blocks are now detected.



\begin{figure}[hb]
  \centering
  \includegraphics[scale=0.3]{figures/Thres_Y_good.png}
  \caption[LABEL] {Correct color thresholding}
\end{figure}

An other solution would have been to set up a constant lighting inside the cell to have more precise ranges for the colors, resulting in a more robust system.



 \section{Edge detection}

	There are different methods to detect the edges in an image. To pick the best one for this application, different methods such as the Canny, log, Prewitt, Roberts, Sobel and zerocross were tested along with their parameters, the threshold, direction and the standard deviation of the filter. \par


	The detection of the edges was based on the resulting image of the color recognition. Below can be seen the color recognition of the blue blocks.

	\begin{figure}[hb]
  \centering
  \includegraphics[scale=0.3]{figures/color_rec_zoom.png}
  \caption[LABEL] {Post color recognition step}
\end{figure}	
	


As seen on the picture above, the shapes of the blocks that resulted from the color recognition step are irregular and so are be the edges. Thus, we used the Canny method that allows us to choose a stantard deviation of its filter in order to smooth the irregularities of the shapes.\par 



The default value of the deviation is $\sqrt{2}$, increasing the deviation will result in smoother lines until getting a round shape.

\begin{figure}[H]
\hfill
\subfigure[Canny default]{
\includegraphics[scale=0.5]{figures/Canny_sqrt2.png}
\label{fig:subim11}}
\hfill
\subfigure[Canny 4]{
\includegraphics[scale=0.5]{figures/Canny_4.png}
\label{fig:subim12}}
\hfill
\subfigure[Canny 10]{
\includegraphics[scale=0.5]{figures/Canny_10.png}
\label{fig:subim12}}
\hfill
\subfigure[Canny 25]{
\includegraphics[scale=0.5]{figures/Canny_25.png}
\label{fig:subim12}}
\hfill

\caption{Canny edge detection method}

\end{figure}




As a result of the tests done, the Canny method with a standard deviation of 4 was the one chosen, giving us smoother lines but not too round corners in order to calculate its position.



 \input{sections/position_rotation.tex}